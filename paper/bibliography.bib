@Article{aldrich2011,
  author={Aldrich, Eric M. and Fernández-Villaverde, Jesús and Ronald Gallant, A. and Rubio-Ramírez, Juan F.},
  title={Tapping the supercomputer under your desk: Solving dynamic equilibrium models with graphics processors},
  journal={Journal of Economic Dynamics and Control},
  year=2011,
  volume={35},
  number={3},
  pages={386-393},
  month={March},
  keywords={ CUDA Dynamic programming Parallelization Growth model Business cycles},
  abstract={This paper shows how to build algorithms that use graphics processing units (GPUs) installed in most modern computers to solve dynamic equilibrium models in economics. In particular, we rely on the compute unified device architecture (CUDA)Â of NVIDIA GPUs. We illustrate the power of the approach by solving a simple real business cycle model with value function iteration. We document improvements in speed of around 200 times and suggest that even further gains are likely.},
  url={http://ideas.repec.org/a/eee/dyncon/v35y2011i3p386-393.html}
}

@TechReport{barney2012parallel,
 author={Blaise Barney},
 year=2012,
 month=jul,
 institution={Lawrence Livermore National Laboratory},
 url={https://computing.llnl.gov/tutorials/parallel_comp}
}

@TechReport{RePEc:nuf:econwp:0416,
  author={Jurgen A. Doornik and Neil Shephard and David F. Hendry},
  title={Parallel Computation in Econometrics: A Simplified Approach},
  year=2004,
  month=Jan,
  institution={Economics Group, Nuffield College, University of Oxford},
  type={Economics Papers},
  url={http://ideas.repec.org/p/nuf/econwp/0416.html},
  number={2004-W16},
  abstract={Parallel computation has a long history in econometric computing, but is not at all wide spread. We believe that a major impediment is the labour cost of coding for parallel architectures. Moreover, programs for specific hardware often become obsolete quite quickly. Our approach is to take a popular matrix programming language (Ox), and implement a message-passing interface using MPI. Next, object-oriented programming allows us to hide the specific parallelization code, so that a program does not need to be rewritten when it is ported from the desktop to a distributed network of computers. Our focus is on so-called embarrassingly parallel computations, and we address the issue of parallel random number generation.},
  keywords={Code optimization; Econometrics; High-performance computing; Matrix-programming language; Monte Carl}
}

@article{hemani2011epigpu,
  title={EpiGPU: exhaustive pairwise epistasis scans parallelized on consumer level graphics cards},
  author={Hemani, G. and Theocharidis, A. and Wei, W. and Haley, C.},
  journal={Bioinformatics},
  volume={27},
  number={11},
  pages={1462--1465},
  year={2011},
  publisher={Oxford Univ Press}
}

@article{vespignani2011modelling,
  title={Modelling dynamical processes in complex socio-technical systems},
  author={Vespignani, A.},
  journal={Nature Physics},
  volume={8},
  number={1},
  pages={32--39},
  year={2011},
  publisher={Nature Publishing Group}
}

@article{davis2011real,
  title={Real-world comparison of CPU and GPU implementations of SNPrank: a network analysis tool for GWAS},
  author={Davis, N.A. and Pandey, A. and McKinney, BA},
  journal={Bioinformatics},
  volume={27},
  number={2},
  pages={284--285},
  year={2011},
  publisher={Oxford Univ Press}
}